k-NN regression: k-NN regression predicts the next value by averaging (or weighting) the targets of the k most similar historical windows according to a distance measure (e.g., Euclidean). In the sliding-window setup, each row encodes the most recent lags of the series; neighbors with similar local patterns contribute to the forecast. The method is nonparametric and relies on appropriate scaling and a sensible choice of k.

Objective: Use KNN (K-Nearest Neighbors) to forecast time series from sliding windows, with normalization, model fitting, and evaluation.

```{r}
# Time Series Regression - KNN

# Installing the package (if needed)
#install.packages("tspredit")
```

```{r}
# Loading the packages
library(daltoolbox)
library(tspredit) 
```


```{r}
# Series for study and sliding windows

data(tsd)
ts <- ts_data(tsd$y, 10)
ts_head(ts, 3)
```

```{r}
# Series visualization
library(ggplot2)
plot_ts(x=tsd$x, y=tsd$y) + theme(text = element_text(size=16))
```

```{r}
# Train-test split and projection (X, y)

samp <- ts_sample(ts, test_size = 5)
io_train <- ts_projection(samp$train)
io_test <- ts_projection(samp$test)
```

```{r}
# Preprocessing (global min-max normalization)

preproc <- ts_norm_gminmax()
```

```{r}
# Training the KNN model

model <- ts_knn(ts_norm_gminmax(), input_size=4, k=3)
model <- fit(model, x=io_train$input, y=io_train$output)
```

```{r}
# Fit evaluation (train)

adjust <- predict(model, io_train$input)
adjust <- as.vector(adjust)
output <- as.vector(io_train$output)
ev_adjust <- evaluate(model, output, adjust)
ev_adjust$mse
```

```{r}
# Forecast on test set (5 steps ahead)

prediction <- predict(model, x=io_test$input[1,], steps_ahead=5)
prediction <- as.vector(prediction)
output <- as.vector(io_test$output)
ev_test <- evaluate(model, output, prediction)
ev_test
```

```{r}
# Plot comparing actual vs fit (train) and forecast (test)

yvalues <- c(io_train$output, io_test$output)
plot_ts_pred(y=yvalues, yadj=adjust, ypre=prediction) + theme(text = element_text(size=16))
```

References
- T. Cover and P. Hart (1967). Nearest neighbor pattern classification. IEEE Transactions on Information Theory, 13(1), 21â€“27.
