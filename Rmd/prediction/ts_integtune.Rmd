Integrated time series tuning: The integrated tuner composes preprocessing, windowing, and a base learner, then searches over their hyperparameters jointly. Evaluation uses time-aware resampling to avoid look-ahead bias. This unified approach simplifies model selection by returning a fitted pipeline configured with the best-scoring setting on the training data.

What you will learn
- Create sliding windows suitable for supervised learning
- Split the data into train/test respecting time order
- Define a search space and run integrated tuning
- Inspect evaluation metrics and visualize predictions


Objectives: Integrated tuning automates hyperparameter search for time-series learners in a single pipeline. It handles preprocessing, window size, and model hyperparameters, then evaluates and returns the best configuration for your training data.

```{r}
# Install tspredit if needed
#install.packages("tspredit")
```

```{r}
# Load packages
library(daltoolbox)
library(tspredit) 
```


```{r}
# Create a simple cosine series for demonstration

i <- seq(0, 25, 0.25)
x <- cos(i)
```

```{r}
# Visualize the time series
plot_ts(x=i, y=x) + theme(text = element_text(size=16))
```



```{r}
# Sliding windows

# Create a sliding-window matrix for supervised learning.
# Each row contains 10 attributes (t9..t0) representing the last 10 observations.
sw_size <- 10
ts <- ts_data(x, sw_size)
ts_head(ts, 3)
```

```{r}
# Data sampling (train/test split)

test_size <- 1                  # keep last step for testing
samp <- ts_sample(ts, test_size)
ts_head(samp$train, 3)
ts_head(samp$test)
```

```{r}
# Define integrated tuning

# We will:
# - search over input window sizes (3..5)
# - use ELM as the base model
# - apply global min-max normalization as preprocessing
# - explore ranges for hidden units and activation function

tune <- ts_integtune(input_size=c(3:5), base_model = ts_elm(), preprocess = list(ts_norm_gminmax()),
                     ranges = list(nhid = 1:5, actfun=c('sig', 'radbas', 'tribas', 'relu', 'purelin')))

```

```{r}
# Fit the tuned pipeline on training data

io_train <- ts_projection(samp$train)
model <- fit(tune, x=io_train$input, y=io_train$output)
```

```{r}
# Evaluate training adjustment (in-sample)

adjust <- predict(model, io_train$input)
ev_adjust <- evaluate(model, io_train$output, adjust)
print(head(ev_adjust$metrics))
```

```{r}
# Forecast on the test segment

steps_ahead <- 1
io_test <- ts_projection(samp$test)
prediction <- predict(model, x=io_test$input, steps_ahead=steps_ahead)
prediction <- as.vector(prediction)

output <- as.vector(io_test$output)
if (steps_ahead > 1)
    output <- output[1:steps_ahead]

print(sprintf("%.2f, %.2f", output, prediction))
```

```{r}
# Evaluate test performance

ev_test <- evaluate(model, output, prediction)
print(head(ev_test$metrics))
print(sprintf("smape: %.2f", 100*ev_test$metrics$smape))
```

```{r}
# Plot results

yvalues <- c(io_train$output, io_test$output)
plot_ts_pred(y=yvalues, yadj=adjust, ypre=prediction) + theme(text = element_text(size=16))
```

```{r}
# Example hyperparameter ranges by model

# ELM
ranges_elm <- list(nhid = 1:20, actfun=c('sig', 'radbas', 'tribas', 'relu', 'purelin'))

# MLP
ranges_mlp <- list(size = 1:10, decay = seq(0, 1, 1/9), maxit=10000)

# RF
ranges_rf <- list(nodesize=1:10, ntree=1:10)

# SVM
ranges_svm <- list(kernel=c("radial", "poly", "linear", "sigmoid"), epsilon=seq(0, 1, 0.1), cost=seq(20, 100, 20))

# LSTM
ranges_lstm <- list(input_size = 1:10, epochs=10000)

# CNN
ranges_cnn <- list(input_size = 1:10, epochs=10000)
```

References
- Salles, R., Pacitti, E., Bezerra, E., Marques, C., Pacheco, C., Oliveira,
C., Porto, F., Ogasawara, E. (2023). TSPredIT: Integrated Tuning of Data
Preprocessing and Time Series Prediction Models. Lecture Notes in Computer Science.
